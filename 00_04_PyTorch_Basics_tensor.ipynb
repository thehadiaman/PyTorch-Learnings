{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f0748e-9bce-491e-8921-a63c37a750eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b291370-5361-464a-a60b-f3502a9d5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch    : 2.7.1+cu118\n",
      "Pandas     : 2.3.2\n",
      "NumPy      : 2.3.3\n",
      "Matplotlib : 3.10.6\n"
     ]
    }
   ],
   "source": [
    "# Check versions to clarify if all required modules are installed and imported\n",
    "print('PyTorch    :', torch.__version__)\n",
    "print('Pandas     :', pd.__version__)\n",
    "print('NumPy      :', np.__version__)\n",
    "print('Matplotlib :', matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daeb23c-72bb-41b3-b62f-05cabc1f7804",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### TENSOR\n",
    "\n",
    "##### Study material:\n",
    "* https://www.mathsisfun.com/definitions/tensor.html\n",
    "* https://www.youtube.com/watch?v=f5liqUk0ZTw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e33e1f-1264-44f6-a0c8-46b64beafc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 5],\n",
      "        [3, 2]])\n",
      "tensor([[[2, 6, 5],\n",
      "         [7, 4, 1],\n",
      "         [4, 9, 7]],\n",
      "\n",
      "        [[5, 4, 7],\n",
      "         [1, 3, 6],\n",
      "         [2, 5, 2]]])\n",
      "torch.Size([2, 2])\n",
      "torch.Size([2, 3, 3])\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Matrix\n",
    "X = torch.tensor(\n",
    "    [\n",
    "        [4, 5],\n",
    "        [3, 2]\n",
    "    ]\n",
    ")\n",
    "Y = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [2, 6, 5],\n",
    "            [7, 4, 1],\n",
    "            [4, 9, 7]\n",
    "        ],\n",
    "        [\n",
    "            [5, 4, 7],\n",
    "            [1, 3, 6],\n",
    "            [2, 5, 2]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Print the properties of matrix tensor\n",
    "print(X)\n",
    "print(Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X.ndim) # Dimensions of x\n",
    "print(Y.ndim) # Dimensions of y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc40f33-a9c1-4287-8e52-cdd5c402a8bc",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb4a5da-6f2a-4362-88b1-8697f3c79194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4948, 0.0242, 0.5824],\n",
       "         [0.6086, 0.8682, 0.0625],\n",
       "         [0.1876, 0.5009, 0.1422]],\n",
       "\n",
       "        [[0.3455, 0.3849, 0.6526],\n",
       "         [0.7408, 0.6279, 0.1730],\n",
       "         [0.1528, 0.8090, 0.7376]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAND_TENSOR = torch.rand(2, 3, 3)\n",
    "RAND_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50847cf-b66b-4a83-8bf9-5f4e09b9d810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random image size tensor\n",
    "RAND_IMG_SIZE_TENSOR = torch.rand(size=(10, 10, 3)) # Height, Width and Color channels (R, G and B)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(RAND_IMG_SIZE_TENSOR)\n",
    "plt.title(\"Random Image\")\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1fd177-c5aa-4481-a1c3-c0746569f838",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### Zeros & Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2f4629-5501-4197-ac92-3736ad43b674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Zeros\n",
    "ZEROS = torch.zeros(5, 5)\n",
    "\n",
    "print(ZEROS)\n",
    "print(ZEROS.dtype) # Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258781ab-4731-42c0-bc31-d96a8e6e5209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Ones\n",
    "ONES = torch.ones(5, 5)\n",
    "\n",
    "print(ONES)\n",
    "print(ONES.dtype) # Data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e230b17d-7925-4a9f-b18d-a6b94cc9e7bb",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------\n",
    "### Range of tensors and Tensor like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c964fb11-da49-474f-b1b2-55d017fe903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range\n",
    "\n",
    "RANGE_TENSOR = torch.arange(0, 10, 2)\n",
    "RANGE_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aad5b94-e905-4de8-93f7-ecc8567f02b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "tensor([129972425473072,      1188280352,      1182718208,               0,\n",
      "                      0])\n",
      "torch.Size([5]) torch.Size([5]) torch.Size([5]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# Like\n",
    "LIKE_ZEROS_TENSOR = torch.zeros_like(RANGE_TENSOR)\n",
    "LIKE_ONES_TENSOR = torch.ones_like(RANGE_TENSOR)\n",
    "LIKE_EMPTY_TENSOR = torch.empty_like(RANGE_TENSOR)\n",
    "\n",
    "print(LIKE_ZEROS_TENSOR)\n",
    "print(LIKE_ONES_TENSOR)\n",
    "print(LIKE_EMPTY_TENSOR)\n",
    "\n",
    "print(RANGE_TENSOR.shape, LIKE_ZEROS_TENSOR.shape, LIKE_ONES_TENSOR.shape, LIKE_EMPTY_TENSOR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223c458-5e1f-44ab-9a60-96df4f9e4fdc",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "### Tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21c5fdaf-848d-4abe-9ca4-12b898b21377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.]) torch.float32\n",
      "tensor([3., 6., 9.], dtype=torch.float64) torch.float64\n",
      "tensor([3, 6, 9], dtype=torch.int16) torch.int16\n"
     ]
    }
   ],
   "source": [
    "# Float 32 tensor\n",
    "FLOAT_32_TENSOR = torch.tensor([3, 6, 9], dtype=torch.float32)\n",
    "\n",
    "# Float 64 tensor\n",
    "FLOAT_64_TENSOR = torch.tensor([3, 6, 9], dtype=torch.float64)\n",
    "\n",
    "# Float 64 tensor\n",
    "INT_16_TENSOR = torch.tensor([3, 6, 9], dtype=torch.int16)\n",
    "\n",
    "print(FLOAT_32_TENSOR, FLOAT_32_TENSOR.dtype)\n",
    "print(FLOAT_64_TENSOR, FLOAT_64_TENSOR.dtype)\n",
    "print(INT_16_TENSOR, INT_16_TENSOR.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ca5052-13df-417c-ae55-3d33079079e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.], dtype=torch.float16) torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Float 16 tensor\n",
    "FLOAT_16_TENSOR = FLOAT_32_TENSOR.type(torch.float16) # instead of torch.float16 we can also use torch.half\n",
    "print(FLOAT_16_TENSOR, FLOAT_16_TENSOR.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93d838b-ad84-4d9e-8d2f-a21bed19a043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.], dtype=torch.float16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLOAT_16_TENSOR * INT_16_TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ee018-4edb-43d3-a00a-c26dd60efa5e",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "### Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd8f9d24-d7a4-4cc1-8721-bf4f1c42b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3721, 0.2732, 0.9086, 0.4246],\n",
      "        [0.5371, 0.3783, 0.2225, 0.8600],\n",
      "        [0.5377, 0.9653, 0.1184, 0.5974]])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a simple randome tensor\n",
    "X_TENSOR = torch.rand(3, 4)\n",
    "\n",
    "# Tensor\n",
    "print(X_TENSOR)\n",
    "\n",
    "# Tensor size\n",
    "print(X_TENSOR.size())\n",
    "\n",
    "# Shape of tensor\n",
    "print(X_TENSOR.shape)\n",
    "\n",
    "# Device tensor is on\n",
    "print(X_TENSOR.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa7c10a-899e-4ea4-ac38-5424ed8bb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem ðŸ§ \n",
    "# Change the tensor device from CPU to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff5a1e6c-edfb-495a-9d70-c9061e6476fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TENSOR = torch.tensor(1)\n",
    "print(X_TENSOR.device)\n",
    "Y_TENSOR = torch.tensor(2)\n",
    "print(Y_TENSOR.device)\n",
    "# Check if cuda available (Cuda can help us to use nvidia GPT)\n",
    "if torch.cuda.is_available():\n",
    "    X_TENSOR = X_TENSOR.to(torch.device(\"cuda\"))\n",
    "\n",
    "Z_TENSOR = X_TENSOR + Y_TENSOR\n",
    "print(Z_TENSOR) \n",
    "Z_TENSOR.device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
